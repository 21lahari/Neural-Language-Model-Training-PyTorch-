# -*- coding: utf-8 -*-
"""nlm_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OAAyUrAEqmDmZsy-h7TVoWgzZSI8A3B2

**Underfitting Model**
"""

!python train_lm.py --data_path dataset.txt --save_dir runs/underfit --epochs 5 \
--batch_size 64 --seq_len 20 --embed 32 --hidden 32 --nlayers 1 --dropout 0.0 --lr 5e-3 --min_freq 1

"""**BESTFIT**"""

!python train_lm.py --data_path dataset.txt --save_dir runs/bestfit_quick --epochs 10 \
--batch_size 64 --seq_len 20 --embed 96 --hidden 192 --nlayers 1 --dropout 0.4 \
--lr 1e-3 --early_stop 3 --min_freq 2 --clip_grad 0.5

"""**Overfitting**"""

!python train_lm.py --data_path dataset.txt --save_dir runs/overfit --epochs 3 --batch_size 8 --seq_len 25 --embed 128 --hidden 256 --nlayers 2 --dropout 0.0 --lr 0.001

"""**OUTPUT GRAPHS**"""

# plot_all_runs.py
import json, os
import matplotlib.pyplot as plt

runs = {
    "underfit": "runs/underfit/results.json",
    "overfit": "runs/overfit/results.json",
    "bestfit": "runs/bestfit_quick/results.json"
}

plt.figure(figsize=(12,8))

for i,(name,path) in enumerate(runs.items(),1):
    if not os.path.exists(path):
        print("Missing:", path)
        continue
    with open(path) as f:
        r = json.load(f)
    train = r.get("train_loss", [])
    val = r.get("val_loss", [])
    epochs = list(range(1, 1+max(len(train), len(val))))
    plt.subplot(3,1,i)
    if train: plt.plot(range(1,1+len(train)), train, label="train")
    if val: plt.plot(range(1,1+len(val)), val, label="val")
    plt.title(name)
    plt.xlabel("epoch")
    plt.ylabel("loss")
    plt.legend()
plt.tight_layout()
plt.savefig("all_three_loss_curves.png", dpi=200)
print("Saved all_three_loss_curves.png")

"""**COMPARISION TABLE**"""

import pandas as pd
import json, os
from IPython.display import display, HTML

# --- Load results from JSON files ---
runs_data = {
    "underfit": "runs/underfit/results.json",
    "overfit": "runs/overfit/results.json",
    "bestfit": "runs/bestfit_quick/results.json"
}

results = []
for name, path in runs_data.items():
    if os.path.exists(path):
        with open(path) as f:
            r = json.load(f)
        results.append({
            "Model": name,
            "Test Loss": r.get("test_loss"),
            "Test Perplexity": r.get("test_ppl")
        })
    else:
        results.append({
            "Model": name,
            "Test Loss": None,
            "Test Perplexity": None
        })

# --- Convert to DataFrame ---
df = pd.DataFrame(results)

# --- Style the table ---
styled = df.style.set_table_styles([
    {"selector": "th", "props": [("background-color", "#333"), ("color", "white")]},
    {"selector": "td", "props": [("padding", "5px")]}
]).set_properties(**{"border": "1px solid black"})

display(styled)

# --- Determine BEST model automatically ---
valid_rows = df.dropna()

if not valid_rows.empty:
    best_row = valid_rows.loc[valid_rows["Test Perplexity"].idxmin()]
    best_model = best_row["Model"]
    best_loss = best_row["Test Loss"]
    best_ppl = best_row["Test Perplexity"]

    print("\nðŸ“Œ BEST MODEL RESULTS")
    print("------------------------------")
    print(f"Best Model: {best_model}")
    print(f"Test Loss: {best_loss}")
    print(f"Test Perplexity: {best_ppl}")

    print("\nâœ… Why this is the best model?")
    print(f"- It has the LOWEST test perplexity ({best_ppl}), which means it generalizes best.")
    print("- Lower perplexity = better predictions on unseen data.")
    print("- Therefore, this model is neither underfitting nor overfitting.")
else:
    print("No valid results found.")